{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/parth/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/parth/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DELIM = '^'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_sentences = brown.tagged_sents(tagset='universal')\n",
    "all_tags = list(set([tag for sentence in tagged_sentences for _, tag in sentence]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel:\n",
    "\n",
    "    def __init__(self, sentences = []):\n",
    "        self.sentences = sentences\n",
    "        self._find_tags()\n",
    "        self.compute_transition_probabilities()\n",
    "        self.compute_emmision_probabilities()\n",
    "    \n",
    "    def _find_tags(self):\n",
    "        self.tags = list(set( [ word_tag[1] for sentence in tagged_sentences for word_tag in sentence ] ))\n",
    "    \n",
    "    def compute_transition_probabilities(self):\n",
    "        T = defaultdict(lambda: defaultdict(lambda:0))\n",
    "        # T = dict of dicts\n",
    "        # T[tcurr] = dict\n",
    "        # T[tcurr][tprev] = integet with default value as 0\n",
    "        TC = defaultdict(lambda : 0)\n",
    "        # TC (tag count) = dict\n",
    "        # TC[tag] = integer with default value as 0\n",
    "        \n",
    "        for sentence in self.sentences:\n",
    "            # skip first word for now\n",
    "            prev_word = (START_DELIM, START_DELIM)\n",
    "            for word in sentence:\n",
    "                T[word[1]][prev_word[1]] += 1\n",
    "                TC[word[1]] += 1\n",
    "                prev_word = word\n",
    "        \n",
    "        TC[START_DELIM] = len(self.sentences)\n",
    "\n",
    "        for curr_tag in T:\n",
    "            for prev_tag in T[curr_tag]:\n",
    "                if curr_tag in T and prev_tag in T[curr_tag]:\n",
    "                    T[curr_tag][prev_tag] = T[curr_tag][prev_tag] / TC[prev_tag]\n",
    "        \n",
    "        self.T = T\n",
    "        self.TC = TC\n",
    "    \n",
    "    def compute_emmision_probabilities(self):\n",
    "        W = defaultdict(lambda: defaultdict(lambda:0))\n",
    "        # W = dict of dicts\n",
    "        # W[word] = dict\n",
    "        # W[word][tag] = integet with default value as 0        \n",
    "\n",
    "        for sentence in self.sentences:\n",
    "            for word in sentence:\n",
    "                W[word[0]][word[1]] += 1\n",
    "\n",
    "        for word in W.keys():\n",
    "            for tag in W[word].keys():\n",
    "                W[word][tag] = W[word][tag] / self.TC[tag]\n",
    "\n",
    "        self.W = W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(sentence, hmm):\n",
    "    selected_path_and_probs = [{ '^' : ('^' , 1) }]\n",
    "    # tag : ( best_prev_tag , best_prob_if_word_has_this_tag )\n",
    "    \n",
    "    \n",
    "    curr_state_probabilities = {}\n",
    "    for tag in all_tags:\n",
    "        # any tag can be placed for the first word w1\n",
    "        curr_state_probabilities[tag] = ('^', hmm.T[tag].get('^',1e-6) * hmm.W[sentence[0]].get(tag, 1e-6))\n",
    "        \n",
    "    selected_path_and_probs.append(curr_state_probabilities)\n",
    "    \n",
    "    for word in sentence[1:]:\n",
    "        curr_state_probabilities = {}\n",
    "        for curr_tag in all_tags:\n",
    "            curr_max = None\n",
    "            for prev_tag , best_till_prev in selected_path_and_probs[-1].items():\n",
    "                possible_state_prob = best_till_prev[1] * hmm.T[curr_tag].get(prev_tag,1e-6) * hmm.W[word].get(curr_tag, 1e-6)\n",
    "                if not curr_max or possible_state_prob > curr_max:\n",
    "                    curr_state_probabilities[curr_tag] = (prev_tag , possible_state_prob)\n",
    "                    curr_max = possible_state_prob\n",
    "                    \n",
    "        selected_path_and_probs.append(curr_state_probabilities)\n",
    "    \n",
    "    \n",
    "    max_prob = max([ d[1] for d in selected_path_and_probs[-1].values()])\n",
    "    last_tag = None\n",
    "    \n",
    "    for tag in selected_path_and_probs[-1].keys():\n",
    "        if selected_path_and_probs[-1][tag][1] == max_prob:\n",
    "            last_tag = tag\n",
    "    \n",
    "    rev_tag_seq = [last_tag]\n",
    "\n",
    "    for i in range(len(sentence)-1):\n",
    "        ind = -1*(i + 1)\n",
    "        last_tag = selected_path_and_probs[ind][last_tag][0]\n",
    "        rev_tag_seq.append(last_tag)\n",
    "\n",
    "    \n",
    "    return [w for w in reversed(rev_tag_seq)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9558093710520983, 0.9564629191601932, 0.9563745573224082, 0.9561343535119081, 0.9560339919448368]\n",
      "Overall Accuracy (5-Fold Cross-Validation): 0.9562\n",
      "Per POS Tag Accuracy:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NUM       0.97      0.91      0.94     14874\n",
      "        NOUN       0.96      0.95      0.95    275558\n",
      "         ADJ       0.91      0.91      0.91     83721\n",
      "        VERB       0.97      0.94      0.96    182750\n",
      "         DET       0.95      0.99      0.97    137019\n",
      "           X       0.80      0.49      0.60      1386\n",
      "         ADV       0.91      0.89      0.90     56239\n",
      "         PRT       0.91      0.91      0.91     29829\n",
      "         ADP       0.95      0.97      0.96    144766\n",
      "        PRON       0.95      0.98      0.97     49334\n",
      "        CONJ       0.99      0.99      0.99     38151\n",
      "           .       0.99      1.00      1.00    147565\n",
      "\n",
      "    accuracy                           0.96   1161192\n",
      "   macro avg       0.94      0.91      0.92   1161192\n",
      "weighted avg       0.96      0.96      0.96   1161192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# perform k-fold cross validation\n",
    "NUM_FOLDS = 5\n",
    "kf = KFold(NUM_FOLDS , shuffle=  True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "all_true_tags = []\n",
    "all_predicted_tags = []\n",
    "\n",
    "\n",
    "for train_indices, test_indices in kf.split(tagged_sentences):\n",
    "    train_data = [tagged_sentences[i] for i in train_indices]\n",
    "    test_data = [tagged_sentences[i] for i in test_indices]\n",
    "\n",
    "    hmm = HiddenMarkovModel(train_data)\n",
    "\n",
    "    true_tags = []\n",
    "    predicted_tags = []\n",
    "    \n",
    "    for sentence in test_data:\n",
    "        words = [word[0] for word in sentence]\n",
    "        true_tags += [word[1] for word in sentence]\n",
    "        predicted_tags += Viterbi(words,hmm)\n",
    "    \n",
    "    all_true_tags += true_tags\n",
    "    all_predicted_tags += predicted_tags\n",
    "    \n",
    "    accuracies.append(accuracy_score(true_tags, predicted_tags))\n",
    "\n",
    "print(accuracies)\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "print(f\"Overall Accuracy (5-Fold Cross-Validation): {overall_accuracy:.4f}\")\n",
    "\n",
    "report = classification_report(all_true_tags, all_predicted_tags, labels=all_tags)\n",
    "print(\"Per POS Tag Accuracy:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^ DET NOUN VERB VERB ADP DET ADJ NOUN\n"
     ]
    }
   ],
   "source": [
    "tags_seq = Viterbi(\"The boat was sailing in the pacific ocean\".split(\" \"),hmm)\n",
    "print(' '.join(tags_seq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
